{
 "cells": [
  {
   "cell_type": "code",
   "id": "colab-mount-drive",
   "metadata": {},
   "source": [
    "# Mount Google Drive\n",
    "# If already mounted this will show \"Drive is already mounted\" ‚Äî that's fine.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "colab-install-deps",
   "metadata": {},
   "source": [
    "# Install packages that are not pre-installed in Colab\n",
    "# (torch, torchvision, numpy, Pillow, requests are already available)\n",
    "!pip install -q git+https://github.com/openai/CLIP.git ftfy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# Download Uppsala Collection & Semantic Image Search with CLIP\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "1. **Download** the Uppsala University collection from Europeana (thumbnail resolution)\n",
    "2. **Learn** how CLIP connects images and text\n",
    "3. **Search** the collection using natural language (e.g., \"waterbody\", \"portrait\")\n",
    "4. **Explore** how different queries find different images\n",
    "\n",
    "---\n",
    "\n",
    "## What is CLIP?\n",
    "\n",
    "**CLIP** (Contrastive Language-Image Pre-training) is a neural network trained by OpenAI that learns to connect images and text. It can:\n",
    "\n",
    "- **Understand images** by converting them into numerical representations (embeddings)\n",
    "- **Understand text** by converting descriptions into the same embedding space\n",
    "- **Match** images and text by measuring how similar their embeddings are\n",
    "\n",
    "This allows us to search for images using natural language descriptions like:\n",
    "- \"a painting of a stormy sea\"\n",
    "- \"winter landscape with snow\"\n",
    "- \"flowers in a vase\"\n",
    "\n",
    "### How CLIP Works\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    subgraph Input\n",
    "        IMG[\"üñºÔ∏è Image\"]\n",
    "        TXT[\"üìù Text\\n'a river landscape'\"]\n",
    "    end\n",
    "    \n",
    "    subgraph CLIP[\"CLIP Model\"]\n",
    "        IE[\"Image\\nEncoder\"]\n",
    "        TE[\"Text\\nEncoder\"]\n",
    "    end\n",
    "    \n",
    "    subgraph Embeddings[\"Embedding Space\"]\n",
    "        IV[\"[0.12, -0.45, 0.78, ...]\"]\n",
    "        TV[\"[0.11, -0.42, 0.81, ...]\"]\n",
    "    end\n",
    "    \n",
    "    SIM[\"üìä Cosine\\nSimilarity\\n= 0.94\"]\n",
    "    \n",
    "    IMG --> IE --> IV\n",
    "    TXT --> TE --> TV\n",
    "    IV --> SIM\n",
    "    TV --> SIM\n",
    "```\n",
    "\n",
    "The key insight: **similar concepts end up close together** in embedding space, whether they come from images or text!\n",
    "\n",
    "---\n",
    "\n",
    "## Pre-calculated Embeddings\n",
    "\n",
    "Computing image embeddings requires significant computational resources (ideally a GPU). For this workshop, we use **pre-calculated embeddings**:\n",
    "\n",
    "- Image embeddings were computed beforehand by the instructor\n",
    "- You only need to compute **text embeddings** (fast on any laptop)\n",
    "- This makes the workshop accessible on any hardware!\n",
    "\n",
    "If you want to compute your own embeddings, see **Notebook 04 (Advanced)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# External libraries\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import display, Image, HTML\n",
    "\n",
    "# Import CLIP\n",
    "try:\n",
    "    import torch\n",
    "    import clip\n",
    "    CLIP_AVAILABLE = True\n",
    "    print(f\"‚úì CLIP loaded successfully!\")\n",
    "except ImportError:\n",
    "    CLIP_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è CLIP not installed.\")\n",
    "    print(\"  Install with: pip install git+https://github.com/openai/CLIP.git torch torchvision\")\n",
    "\n",
    "# Select compute device: CUDA GPU > Apple Silicon GPU > CPU\n",
    "if CLIP_AVAILABLE:\n",
    "    if torch.cuda.is_available():\n",
    "        DEVICE = 'cuda'\n",
    "        print(f\"‚úì NVIDIA GPU (CUDA): {torch.cuda.get_device_name(0)}\")\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        DEVICE = 'mps'\n",
    "        print(\"‚úì Apple Silicon GPU (MPS) ‚Äî good performance!\")\n",
    "    else:\n",
    "        DEVICE = 'cpu'\n",
    "        print(\"‚ÑπÔ∏è No GPU detected. Using CPU ‚Äî fine for text search in this workshop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up base paths\n",
    "PROJECT_ROOT = Path(\"/content/drive/MyDrive/Distant_viewing\")\n",
    "DATA_DIR     = PROJECT_ROOT / \"data\"\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data dir:     {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "download-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Download from a Swedish collection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0bc7e0",
   "metadata": {},
   "source": [
    "  1. Swedish National Heritage Board                            (1,414,618 items)\n",
    "  2. Nordic Museum Foundation                                   (351,553 items)\n",
    "  3. Malm√∂ Museum                                               (288,308 items)\n",
    "  4. Museum of Ethnography                                      (271,525 items)\n",
    "  5. Museum of World Culture                                    (230,176 items)\n",
    "  6. Upplands Museum                                            (218,928 items)\n",
    "  7. Jamtli                                                     (173,095 items)\n",
    "  8. Museum of Gothenburg                                       (171,960 items)\n",
    "  9. Swedish National Museum of Science and Technology          (150,809 items)\n",
    " 10. Swedish Railway Museum                                     (145,093 items)\n",
    " 11. Naval Museum                                               (143,623 items)\n",
    " 12. Bohusl√§n Museum                                            (140,521 items)\n",
    " 13. G√§vleborg County Museum                                    (133,207 items)\n",
    " 14. Kulturen                                                   (130,732 items)\n",
    " 15. √ñrebro County Museum                                       (125,272 items)\n",
    " 16. V√§sterg√∂tlands Museum                                      (117,479 items)\n",
    " 17. Army Museum                                                (114,513 items)\n",
    " 18. S√∂rmland Museum                                            (107,177 items)\n",
    " 19. National Maritime Museum                                   (103,829 items)\n",
    " 20. V√§nersborgs museum                                         (103,249 items)\n",
    " 21. The Museum of Mediterranean and Near Eastern Antiquities... (74,761 items)\n",
    " 22. Museum of Far Eastern Antiquities                          (74,426 items)\n",
    " 23. Uppsala University                                         (74,233 items)\n",
    " 24. H√§lsinglands Museum                                        (73,678 items)\n",
    " 25. Swedish Centre for Architecture and Design                 (67,581 items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Setup (same as Notebook 01)\n",
    "BASE_URL = \"https://api.europeana.eu/record/v2\"\n",
    "\n",
    "# Load API key\n",
    "NOTEBOOK_DIR = PROJECT_ROOT\n",
    "API_KEY_LOCATIONS = [\n",
    "    NOTEBOOK_DIR / \"api-key-europeana.txt\",\n",
    "    PROJECT_ROOT / \"misc\" / \"api-key-europeana.txt\",\n",
    "]\n",
    "\n",
    "API_KEY = \"api2demo\"\n",
    "for key_file in API_KEY_LOCATIONS:\n",
    "    if key_file.exists():\n",
    "        with open(key_file, 'r') as f:\n",
    "            custom_key = f.read().strip()\n",
    "            if custom_key and custom_key != \"api2demo\":\n",
    "                API_KEY = custom_key\n",
    "                print(f\"‚úì API key loaded from {key_file}\")\n",
    "                break\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Using demo API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API and helper functions\n",
    "\n",
    "def search_europeana(query=\"*\", rows=12, reusability=\"open\", qf=None,\n",
    "                     profile=\"standard\", cursor=None, theme=None):\n",
    "    \"\"\"Search the Europeana collection.\"\"\"\n",
    "    url = f\"{BASE_URL}/search.json\"\n",
    "    params = {\n",
    "        \"wskey\": API_KEY,\n",
    "        \"query\": query,\n",
    "        \"rows\": min(rows, 100),\n",
    "        \"profile\": profile\n",
    "    }\n",
    "    if reusability:\n",
    "        params[\"reusability\"] = reusability\n",
    "    if qf:\n",
    "        params[\"qf\"] = qf\n",
    "    if cursor:\n",
    "        params[\"cursor\"] = cursor\n",
    "    if theme:\n",
    "        params[\"theme\"] = theme\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_item_title(item):\n",
    "    if 'title' in item and item['title']:\n",
    "        return item['title'][0] if isinstance(item['title'], list) else item['title']\n",
    "    return \"Untitled\"\n",
    "\n",
    "\n",
    "def get_item_creator(item):\n",
    "    if 'dcCreator' in item and item['dcCreator']:\n",
    "        return item['dcCreator'][0] if isinstance(item['dcCreator'], list) else item['dcCreator']\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def get_item_year(item):\n",
    "    if 'year' in item and item['year']:\n",
    "        return item['year'][0] if isinstance(item['year'], list) else item['year']\n",
    "    return \"n.d.\"\n",
    "\n",
    "\n",
    "def get_item_preview(item):\n",
    "    if 'edmPreview' in item and item['edmPreview']:\n",
    "        return item['edmPreview'][0] if isinstance(item['edmPreview'], list) else item['edmPreview']\n",
    "    return None\n",
    "\n",
    "\n",
    "def sanitize_filename(name):\n",
    "    if not name:\n",
    "        return \"unknown\"\n",
    "    safe = \"\".join(c for c in name if c.isalnum() or c in ' ._-')\n",
    "    return safe.strip()[:80]\n",
    "\n",
    "\n",
    "print(\"‚úì Functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab391d6",
   "metadata": {},
   "source": [
    "### Function definition: download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35ae92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_collection(\n",
    "    collection_name,\n",
    "    theme=None,\n",
    "    keyword=None,\n",
    "    max_images=200,\n",
    "    output_dir=None,\n",
    "    delay=0.3\n",
    "):\n",
    "    \"\"\"\n",
    "    Download thumbnail images from a specific Europeana institution.\n",
    "\n",
    "    Parameters:\n",
    "        collection_name : DATA_PROVIDER name in Europeana (e.g. \"Museum of Gothenburg\")\n",
    "        theme           : Thematic collection filter (e.g. \"art\"), or None for all\n",
    "        keyword         : Optional keyword to narrow results (e.g. \"river\"), or None\n",
    "        max_images      : Maximum number of images to download\n",
    "        output_dir      : Path to save images (auto-generated from params if None)\n",
    "        delay           : Seconds to wait between requests (be polite to the server)\n",
    "\n",
    "    Returns:\n",
    "        List of Path objects for all images in the output directory after download\n",
    "    \"\"\"\n",
    "    # Build output directory name from params if not given explicitly\n",
    "    if output_dir is None:\n",
    "        parts = [collection_name.replace(' ', '_')]\n",
    "        if theme:\n",
    "            parts.append(theme)\n",
    "        if keyword:\n",
    "            parts.append(keyword)\n",
    "        output_dir = DATA_DIR / \"images\" / \"_\".join(parts)\n",
    "\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build API query\n",
    "    qf    = [f'DATA_PROVIDER:\"{collection_name}\"', \"TYPE:IMAGE\"]\n",
    "    query = keyword or \"*\"\n",
    "\n",
    "    print(f\"üì• {collection_name}\")\n",
    "    if theme:   print(f\"   theme   = {theme}\")\n",
    "    if keyword: print(f\"   keyword = {keyword}\")\n",
    "    print(f\"   max     = {max_images}\")\n",
    "    print(f\"   folder  ‚Üí {output_dir.name}/\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Check total available before starting\n",
    "    check = search_europeana(query=query, rows=1, qf=qf, theme=theme, reusability=\"open\")\n",
    "    if not check or not check.get('success'):\n",
    "        print(\"‚ùå Could not reach API\")\n",
    "        return []\n",
    "    total_available = check['totalResults']\n",
    "    print(f\"‚úì {total_available:,} images available\")\n",
    "    print()\n",
    "\n",
    "    # Paginate and download\n",
    "    cursor       = \"*\"\n",
    "    processed    = 0\n",
    "    new_dl       = 0\n",
    "\n",
    "    while processed < max_images:\n",
    "        batch  = min(100, max_images - processed)\n",
    "        result = search_europeana(\n",
    "            query=query, rows=batch, qf=qf, theme=theme,\n",
    "            reusability=\"open\", cursor=cursor\n",
    "        )\n",
    "        if not result or not result.get('items'):\n",
    "            break\n",
    "\n",
    "        for item in result['items']:\n",
    "            if processed >= max_images:\n",
    "                break\n",
    "\n",
    "            preview_url = get_item_preview(item)\n",
    "            if not preview_url:\n",
    "                processed += 1\n",
    "                continue\n",
    "\n",
    "            item_id    = item.get('id', 'unknown').replace('/', '_')\n",
    "            safe_title = sanitize_filename(get_item_title(item))[:40]\n",
    "            filepath   = output_dir / f\"{item_id}_{safe_title}.jpg\"\n",
    "\n",
    "            if filepath.exists() and filepath.stat().st_size > 0:\n",
    "                processed += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                resp = requests.get(preview_url, timeout=20)\n",
    "                resp.raise_for_status()\n",
    "                with open(filepath, 'wb') as f:\n",
    "                    f.write(resp.content)\n",
    "                new_dl += 1\n",
    "                if new_dl % 50 == 0:\n",
    "                    print(f\"  {new_dl} new images downloaded...\")\n",
    "                time.sleep(delay)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            processed += 1\n",
    "\n",
    "        cursor = result.get('nextCursor')\n",
    "        if not cursor:\n",
    "            break\n",
    "\n",
    "    all_files = list(output_dir.glob(\"*.jpg\"))\n",
    "    existing  = len(all_files) - new_dl\n",
    "    print(f\"\\n‚úì Done: {new_dl} new  +  {existing} already existed  =  {len(all_files)} total\")\n",
    "    print(f\"   {output_dir}\")\n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-uppsala",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION ‚Äî change these to switch collection / filter\n",
    "# ============================================================\n",
    "\n",
    "COLLECTION_NAME = \"Museum of Gothenburg\"  # <-- DATA_PROVIDER name in Europeana\n",
    "THEME           = \"art\"                   # <-- \"art\", \"photography\", etc. ‚Äî or None for all\n",
    "SEARCH_KEYWORD  = None                    # <-- extra keyword filter, e.g. \"river\" ‚Äî or None for all\n",
    "MAX_DOWNLOAD    = 200                     # <-- how many images to download\n",
    "DO_DOWNLOAD     = True                  # <-- set to True when ready to download\n",
    "\n",
    "# ============================================================\n",
    "# Auto-generate folder name and file paths from the config above\n",
    "# Examples:\n",
    "#   Museum of Gothenburg + art          ‚Üí  Museum_of_Gothenburg_art/\n",
    "#   Museum of Gothenburg + art + river  ‚Üí  Museum_of_Gothenburg_art_river/\n",
    "# ============================================================\n",
    "\n",
    "_parts = [COLLECTION_NAME.replace(' ', '_')]\n",
    "if THEME:\n",
    "    _parts.append(THEME)\n",
    "if SEARCH_KEYWORD:\n",
    "    _parts.append(SEARCH_KEYWORD)\n",
    "\n",
    "_folder_name = \"_\".join(_parts)\n",
    "\n",
    "COLLECTION_IMAGES_DIR      = DATA_DIR / \"images\"     / _folder_name\n",
    "COLLECTION_EMBEDDINGS_FILE = DATA_DIR / \"embeddings\" / _folder_name / f\"{_folder_name}_clip_embeddings.npz\"\n",
    "\n",
    "COLLECTION_IMAGES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "COLLECTION_EMBEDDINGS_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Collection : {COLLECTION_NAME}\")\n",
    "print(f\"Theme      : {THEME      or '(all)'}\")\n",
    "print(f\"Keyword    : {SEARCH_KEYWORD or '(all)'}\")\n",
    "print(f\"Folder     : {_folder_name}/\")\n",
    "print(f\"Images     : {COLLECTION_IMAGES_DIR}\")\n",
    "print(f\"Embeddings : {COLLECTION_EMBEDDINGS_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007075ba",
   "metadata": {},
   "source": [
    "### Run Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-uppsala",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_DOWNLOAD:\n",
    "    downloaded_files = download_collection(\n",
    "        collection_name = COLLECTION_NAME,\n",
    "        theme           = THEME,\n",
    "        keyword         = SEARCH_KEYWORD,\n",
    "        max_images      = MAX_DOWNLOAD,\n",
    "        output_dir      = COLLECTION_IMAGES_DIR,\n",
    "    )\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Download skipped ‚Äî set DO_DOWNLOAD = True in the config cell to download.\")\n",
    "    existing = list(COLLECTION_IMAGES_DIR.glob(\"*.jpg\"))\n",
    "    if existing:\n",
    "        print(f\"   Found {len(existing)} existing images in {COLLECTION_IMAGES_DIR.name}/\")\n",
    "    else:\n",
    "        print(f\"   No images yet in {COLLECTION_IMAGES_DIR.name}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "\n",
    "1. **How to explore** Swedish cultural institutions in Europeana\n",
    "2. **How to configure** a flexible download (collection, theme, keyword)\n",
    "3. **How folder names** are auto-generated from your configuration\n",
    "4. **How cursor-based pagination** lets you retrieve more than 100 results\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Notebook 03**, you will:\n",
    "- Load the CLIP model\n",
    "- Compute embeddings for your downloaded images\n",
    "- Search the collection using natural language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbac6ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d4d77cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd27d28",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dh-workshop",
   "language": "python",
   "name": "dh-workshop"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
